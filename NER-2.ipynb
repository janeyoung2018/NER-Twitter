{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWEirHfbnvak"
   },
   "source": [
    "# Named Entity Recognition(NER) on Twitter \n",
    "\n",
    "In these notewooks, I will use 5 ways to solve custom Named Entity Recognition (NER) problem on Twitter. NER is a task that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
    "\n",
    "In this dataset, we have 21 different tags for sentences.\n",
    "\n",
    "tags = ['O', 'B-musicartist', 'I-musicartist', 'B-product', 'I-product', 'B-company', 'B-person', 'B-other', 'I-other', 'B-facility',\n",
    "    'I-facility', 'B-sportsteam', 'B-geo-loc', 'I-geo-loc', 'I-company', 'I-person', 'B-movie', 'I-movie', 'B-tvshow', 'I-tvshow',\n",
    "    'I-sportsteam'],\n",
    "\n",
    "where 'B-' and 'I-' prefixes stand for the beginning and inside of the entity, 'O' stands for out of tag or no tag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erwvFKntmMEa"
   },
   "source": [
    "### Models\n",
    "\n",
    "In the following three notebooks, we will use five ways to examine the dataset.\n",
    "\n",
    "- Naive Bayes multinomial model\n",
    "- Conditional Random Fields (CRFs)\n",
    "- Custom SpaCy\n",
    "- <mark>BERT in Spark NLP</mark>\n",
    "- Simple Transformer \n",
    "\n",
    "In this notebook we will discuss BERT in Spark NLP. Embedding with 'bert_base_cased', the  Neural Network architecture behind NerDLApproach is Char CNNs - BiLSTM - CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "Gqb9FQo596cf",
    "outputId": "d97e562b-d975-4261-8c25-7437729291f6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1wdoVFStpJk8",
    "outputId": "05a4d8b4-f71b-4cda-d1cd-f0b1aa8b1911"
   },
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjdgHq-lpjhX"
   },
   "source": [
    "#### Installation(for google colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "OcYren-DplyD",
    "outputId": "d2d139aa-fe01-4e9d-ffe0-f7612d4d37fd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==2.5.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2InYgeppxDG"
   },
   "source": [
    "#### Import libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BTNT5_RsnvbP"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "L2m3hB0wnvbQ",
    "outputId": "d788ffa7-1b96-487f-be75-c831b423061b"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp.start(gpu=True)\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6991MjmnvbS"
   },
   "outputs": [],
   "source": [
    "def start(gpu=False):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"8G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\n",
    "    if gpu:\n",
    "        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp-gpu_2.11:2.5.1\")\n",
    "    else:\n",
    "        builder.config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.1\")\n",
    "\n",
    "    return builder.getOrCreate()\n",
    "\n",
    "  \n",
    "spark = start(gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zuzSHbP8_3-"
   },
   "source": [
    "As we need to fit the form of CoNLL dataset, we add a new column \"pos\" to \"train.txt\" and \"text.txt\". All cells in column \"pos\" are \"NNP\"(Later we won't use this column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "na3Pftr7nvbU",
    "outputId": "c32fd04d-9acf-4d2a-aa95-7f6131c9f115"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "train_data = CoNLL().readDataset(spark, './drive/My Drive/NER/data/train1.txt')\n",
    "train_data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Qv6Jw8PxnvbW",
    "outputId": "edec50df-0ea2-4c00-c477-e47daf089033"
   },
   "outputs": [],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e8FoEWoaaXKl"
   },
   "source": [
    "#### Loading Bert with poolingLayer -2\n",
    "- setPoolingLayer(-2) is better than setPoolingLayer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "FhPCGSgHaXtr",
    "outputId": "7d8a4242-0850-4aff-8016-739e748ac573"
   },
   "outputs": [],
   "source": [
    "bert_annotator = BertEmbeddings.pretrained('bert_base_cased', 'en') \\\n",
    " .setInputCols([\"sentence\",'token'])\\\n",
    " .setOutputCol(\"bert\")\\\n",
    " .setCaseSensitive(False)\\\n",
    " .setPoolingLayer(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Wc1rcz--JOV"
   },
   "source": [
    "Transform test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "AboiAfrgiidA",
    "outputId": "4b8527b4-b443-4c2e-a38d-2df8364497c1"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "test_data = CoNLL().readDataset(spark, './drive/My Drive/NER/data/test1.txt')\n",
    "\n",
    "test_data = bert_annotator.transform(test_data)\n",
    "\n",
    "test_data.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ffQFAnORijSZ",
    "outputId": "395c5ca9-cc29-4b7b-c126-2dff0570af56"
   },
   "outputs": [],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECjaZ7TIcYxi"
   },
   "outputs": [],
   "source": [
    "test_data.write.parquet(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90H6csyU-RWe"
   },
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKPjpRJ8cNue"
   },
   "outputs": [],
   "source": [
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"bert\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(15)\\\n",
    "  .setLr(0.001)\\\n",
    "  .setPo(0.005)\\\n",
    "  .setBatchSize(8)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(1)\\\n",
    "  .setValidationSplit(0.2)\\\n",
    "  .setEvaluationLogExtended(True) \\\n",
    "  .setEnableOutputLogs(True)\\\n",
    "  .setIncludeConfidence(True)\\\n",
    "  .setTestDataset(\"test_withEmbeds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHExF2asacFB"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "    bert_annotator,\n",
    "    nerTagger\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PqyazPRP-cNi"
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pC7fpx4oahFJ",
    "outputId": "1db9b34d-0d4b-4645-9d04-943ab430966d"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "ner_model = pipeline.fit(train_data)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x80QHCVh-ndV"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "R5YXCoFgRosW",
    "outputId": "6a4be7ff-8d20-4ef6-9c7d-992b6e9cd3e6"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predictions_train = ner_model.transform(train_data)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_train = predictions_train.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "        F.expr(\"cols['2']\").alias(\"prediction\")).toPandas()\n",
    "print(time.time()-start)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_u8yAGmvaiWL"
   },
   "outputs": [],
   "source": [
    "predictions_test = ner_model.transform(test_data)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_test = predictions_test.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "        F.expr(\"cols['2']\").alias(\"prediction\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0PVd3Nl4ojSY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4c-WK7c_R3Cq"
   },
   "outputs": [],
   "source": [
    "y_train = df_train.ground_truth.values\n",
    "y_train_pred = df_train.prediction.values\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "classes = classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xO2ecrn_oyh6"
   },
   "outputs": [],
   "source": [
    "y_test = df_test.ground_truth.values\n",
    "y_test_pred = df_test.prediction.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "Ov3pHBGco--x",
    "outputId": "ffd9efef-f6a8-4604-e0f6-cc98dc0833c9"
   },
   "outputs": [],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes = new_classes[:-1]\n",
    "new_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "YXpAvYxPSEcE",
    "outputId": "f52b87c2-2c44-4916-e828-7705b8e538de"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('-' * 20 + ' Train set quality: ' + '-' * 20)\n",
    "print(f1_score(y_pred=y_train_pred, y_true=y_train, labels=classes, average='micro'))\n",
    "print('-' * 20 + ' Test set quality: ' + '-' * 20)\n",
    "print(f1_score(y_pred=y_test_pred, y_true=y_test, labels=classes, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "colab_type": "code",
    "id": "OATBrKSnpGX7",
    "outputId": "7be16b9c-803a-4dd5-f81c-af958ab4fb25"
   },
   "outputs": [],
   "source": [
    "print('-' * 20 + ' Train set quality: ' + '-' * 20)\n",
    "print(classification_report(y_pred=y_train_pred, y_true=y_train, labels=new_classes))\n",
    "print('-' * 20 + ' Test set quality: ' + '-' * 20)\n",
    "print(classification_report(y_pred=y_test_pred, y_true=y_test, labels=new_classes))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week2_NER3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
